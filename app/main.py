import os
import json
from dotenv import load_dotenv
from fastapi import FastAPI
from pydantic import BaseModel
import gradio as gr
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA

# 1. è¼‰å…¥ .env ä¸¦è¨­å®š API KEY
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

# 2. åˆå§‹åŒ– embedding æ¨¡å‹èˆ‡ LLM (GPT-4o)
embedding_model = OpenAIEmbeddings()
llm = ChatOpenAI(model_name="gpt-4o", temperature=0.7)

# 3. è¼‰å…¥ embedding çµæœ (JSON)
with open("data/embedding_results.json", "r", encoding="utf-8") as f:
    embedding_data = json.load(f)

# 4. å»ºç«‹ FAISS å‘é‡è³‡æ–™åº«
texts = [item['file'] for item in embedding_data]
embeddings = [item['embedding'] for item in embedding_data]
faiss_db = FAISS.from_embeddings(list(zip(texts, embeddings)), embedding_model)

# 5. Prompt æ¨¡æ¿
prompt_template = """
ä½ æ˜¯ä¸€ä½ maimai éŠæˆ²å°ˆå®¶ï¼Œæ ¹æ“šä»¥ä¸‹çš„æ”»ç•¥è³‡æ–™ï¼Œå›ç­”ç©å®¶çš„å•é¡Œã€‚
å¦‚æœä½ ä¸çŸ¥é“ç­”æ¡ˆï¼Œè«‹èªªã€Œé€™éƒ¨åˆ†æˆ‘ä¸ç¢ºå®šï¼Œä½†æˆ‘å¯ä»¥å¹«ä½ æŸ¥è©¢æ›´å¤šè³‡æ–™ã€‚ã€ã€‚

æ”»ç•¥è³‡æ–™ï¼š
{context}

å•é¡Œï¼š
{question}

è«‹ç”¨ç°¡æ½”æ¸…æ¥šçš„æ–¹å¼å›ç­”ï¼š
"""

prompt = PromptTemplate(
    input_variables=["context", "question"],
    template=prompt_template,
)

# 6. RAG æŸ¥è©¢æµç¨‹
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=faiss_db.as_retriever(search_kwargs={"k": 5}),
    chain_type="stuff",
    chain_type_kwargs={"prompt": prompt}
)

# 7. Gradio UI
def rag_answer(user_query, history):
    result = qa_chain.invoke({"query": user_query})
    bot_reply = result['result']
    history.append((user_query, bot_reply))
    return history, history

gr_app = gr.Blocks()
with gr_app:
    gr.Markdown("# ğŸ® maimai RAG å•ç­”æ©Ÿå™¨äºº")
    chatbot = gr.Chatbot()
    user_input = gr.Textbox(label="è«‹è¼¸å…¥ä½ çš„å•é¡Œ", placeholder="ä¾‹å¦‚ï¼šä»€éº¼æ˜¯äº”æ˜Ÿï¼Ÿ")
    submit_btn = gr.Button("é€å‡ºå•é¡Œ")
    state = gr.State([])

    submit_btn.click(fn=rag_answer, inputs=[user_input, state], outputs=[chatbot, state])
    user_input.submit(fn=rag_answer, inputs=[user_input, state], outputs=[chatbot, state])

if __name__ == "__main__":
    gr_app.launch(server_name="0.0.0.0", server_port=8000)
